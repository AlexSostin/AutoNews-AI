import argparse
import os
import sys
import re

# Add ai_engine directory to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# Import config first to ensure it's available
try:
    from ai_engine.config import GROQ_API_KEY
except ImportError:
    try:
        from config import GROQ_API_KEY
    except ImportError:
        GROQ_API_KEY = os.getenv('GROQ_API_KEY')

# Import modules
try:
    from ai_engine.modules.downloader import download_audio_and_thumbnail
    from ai_engine.modules.transcriber import transcribe_from_youtube
    from ai_engine.modules.analyzer import analyze_transcript
    from ai_engine.modules.article_generator import generate_article
    from ai_engine.modules.publisher import publish_article
    from ai_engine.modules.downloader import extract_video_screenshots
except ImportError:
    from modules.downloader import download_audio_and_thumbnail
    from modules.transcriber import transcribe_from_youtube
    from modules.analyzer import analyze_transcript
    from modules.article_generator import generate_article
    from modules.publisher import publish_article
    from modules.downloader import extract_video_screenshots

def extract_title(html_content):
    match = re.search(r'<h2>(.*?)</h2>', html_content)
    if match:
        return match.group(1)
    return "New Car Review" 

def main(youtube_url):
    print(f"Starting pipeline for: {youtube_url}")
    
    # 1. Download
    # audio_path, thumbnail_path = download_audio_and_thumbnail(youtube_url)
    
    # 2. Transcribe
    # transcript = transcribe_audio(audio_path)
    
    # For testing without wasting API credits/Time, let's mock if needed
    # transcript = "Mock transcript..."
    
    # 3. Analyze
    # analysis = analyze_transcript(transcript)
    
    # 4. Generate Article
    # article_html = generate_article(analysis)
    
    # Mocking for demonstration since we don't have API keys set up
    article_html = "<h2>2026 Future Car Review</h2><p>This is a generated article with a mockup image.</p>"
    
    # 5. Publish
    title = extract_title(article_html)
    
    # Pass thumbnail_path if we had real download
    # publish_article(title, article_html, image_path=thumbnail_path)
    
    # Mock publish
    publish_article(title, article_html)
    
    print("Pipeline finished.")

def check_duplicate(youtube_url):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ —Å—Ç–∞—Ç—å—é —Å —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ.
    """
    # Setup Django if not configured
    import django
    if not django.apps.apps.ready:
        import os
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        sys.path.append(BASE_DIR)
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'auto_news_site.settings')
        django.setup()
    
    from news.models import Article
    
    existing = Article.objects.filter(youtube_url=youtube_url).first()
    if existing:
        print(f"‚ö†Ô∏è  –°—Ç–∞—Ç—å—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {existing.slug} (ID: {existing.id})")
        return existing
    return None


def generate_article_from_youtube(youtube_url, task_id=None, provider='groq'):
    """
    Generate article from YouTube URL and return article data.
    Used by Django API.
    
    Args:
        youtube_url: YouTube video URL
        task_id: Optional WebSocket task ID for progress updates
        provider: AI provider to use - 'groq' (default) or 'gemini'
    
    –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å:
    - –ü—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ–≥–∞–º–∏
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∞–≤—Ç–æ
    - SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    - WebSocket –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
    - –í—ã–±–æ—Ä–æ–º AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    """
    
    def send_progress(step, progress, message):
        """Send progress update via WebSocket"""
        if not task_id:
            print(f"[{progress}%] {message}")
            return
        try:
            from asgiref.sync import async_to_sync
            from channels.layers import get_channel_layer
            channel_layer = get_channel_layer()
            if channel_layer:
                async_to_sync(channel_layer.group_send)(
                    f"generation_{task_id}",
                    {
                        "type": "send_progress",
                        "step": step,
                        "progress": progress,
                        "message": message
                    }
                )
        except Exception as e:
            print(f"WebSocket progress error: {e}")
    
    try:
        provider_name = "Groq" if provider == 'groq' else "Google Gemini"
        send_progress(1, 5, f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å {provider_name}...")
        print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑: {youtube_url} –∏—Å–ø–æ–ª—å–∑—É—è {provider_name}")
        
        # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        send_progress(1, 10, "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        existing = check_duplicate(youtube_url)
        if existing:
            send_progress(1, 100, "‚ö†Ô∏è –°—Ç–∞—Ç—å—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return {
                'success': False,
                'error': f'–°—Ç–∞—Ç—å—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {existing.title}',
                'article_id': existing.id,
                'duplicate': True
            }
        
        # 1. –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
        send_progress(2, 20, "üìù –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å YouTube...")
        print("üìù –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞...")
        transcript = transcribe_from_youtube(youtube_url)
        
        if not transcript or len(transcript) < 5:
            send_progress(2, 100, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç")
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
        
        send_progress(2, 30, f"‚úì –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ–ª—É—á–µ–Ω ({len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        print(f"‚úì –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ–ª—É—á–µ–Ω ({len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
        send_progress(3, 40, f"üîç –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å {provider_name} AI...")
        print("üîç –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞...")
        analysis = analyze_transcript(transcript, provider=provider)
        
        if not analysis:
            send_progress(3, 100, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å")
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç")
        
        send_progress(3, 50, "‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        print("‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # 2.5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ —Ç–µ–≥–∏ (–ù–û–í–û–ï!)
        send_progress(4, 55, "üè∑Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∏ —Ç–µ–≥–∏...")
        print("üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∏ —Ç–µ–≥–∏...")
        from modules.analyzer import categorize_article, extract_specs_dict
        
        category_name, tag_names = categorize_article(analysis)
        print(f"‚úì –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category_name}")
        print(f"‚úì –¢–µ–≥–∏: {', '.join(tag_names) if tag_names else '–Ω–µ—Ç'}")
        
        # 2.6. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –ë–î (–ù–û–í–û–ï!)
        specs = extract_specs_dict(analysis)
        send_progress(4, 60, f"‚úì {specs['make']} {specs['model']}")
        print(f"‚úì –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {specs['make']} {specs['model']} {specs['year'] or ''}")
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å—é
        send_progress(5, 65, f"‚úçÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —Å {provider_name}...")
        print(f"‚úçÔ∏è  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —Å {provider_name}...")
        article_html = generate_article(analysis, provider=provider)
        
        if not article_html or len(article_html) < 100:
            send_progress(5, 100, "‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏")
            raise Exception("–°—Ç–∞—Ç—å—è –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è")
        
        send_progress(5, 75, "‚úì –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
        print(f"‚úì –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ ({len(article_html)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title = extract_title(article_html)
        
        # 5. –ò–∑–≤–ª–µ–∫–∞–µ–º 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ
        send_progress(6, 80, "üì∏ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...")
        print("üì∏ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –∏–∑ –≤–∏–¥–µ–æ...")
        screenshot_paths = []
        try:
            # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
            screenshots_dir = os.path.join(current_dir, 'output', 'screenshots')
            os.makedirs(screenshots_dir, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –≤–∏–¥–µ–æ
            screenshot_paths = extract_video_screenshots(youtube_url, output_dir=screenshots_dir, count=3)
            
            if screenshot_paths:
                send_progress(6, 85, f"‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(screenshot_paths)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
                print(f"‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(screenshot_paths)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
            else:
                send_progress(6, 85, "‚ö†Ô∏è –°–∫—Ä–∏–Ω—à–æ—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–∫—Ä–∏–Ω—à–æ—Ç—ã")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {e}")
            screenshot_paths = []
        
        # 6. –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        send_progress(7, 90, "üìù –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è...")
        summary_lines = [line for line in analysis.split('\n') if line.startswith('Summary:')]
        if summary_lines:
            summary = summary_lines[0].replace('Summary:', '').strip()[:300]
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ —Å—Ç–∞—Ç—å–∏
            import re
            match = re.search(r'<p>(.*?)</p>', article_html, re.DOTALL)
            if match:
                summary = re.sub(r'<[^>]+>', '', match.group(1))[:300]
            else:
                summary = f"Comprehensive review of the {specs['make']} {specs['model']}"
        
        
        # 6.5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SEO keywords
        from modules.seo_helpers import generate_seo_keywords
        seo_keywords = ''
        
        # Only generate if analysis is a dict (not a string)
        if isinstance(analysis, dict):
            seo_keywords = generate_seo_keywords(analysis, title)
            print(f"‚úì SEO Keywords: {seo_keywords}")
        else:
            print(f"‚ö†Ô∏è Analysis is not a dict, skipping SEO keywords generation")
        
        # 7. –ü—É–±–ª–∏–∫—É–µ–º —Å—Ç–∞—Ç—å—é —Å –ü–û–õ–ù–´–ú–ò –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏
        send_progress(8, 95, "üì§ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        print("üì§ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏...")
        article = publish_article(
            title=title,
            content=article_html,
            summary=summary,
            category_name=category_name,  # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            youtube_url=youtube_url,
            image_paths=screenshot_paths,  # 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ
            tag_names=tag_names,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏
            specs=specs,  # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ
            meta_keywords=seo_keywords  # SEO keywords
        )
        
        send_progress(9, 100, f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {article.title[:50]}...")
        print(f"‚úÖ –°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞! ID: {article.id}, Slug: {article.slug}")
        
        return {
            'success': True,
            'article_id': article.id,
            'title': title,
            'slug': article.slug,
            'category': category_name,
            'tags': tag_names
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            'success': False,
            'error': str(e)
        }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="AI Auto News Generator")
    parser.add_argument("url", help="YouTube Video URL")
    args = parser.parse_args()
    
    main(args.url)
