import argparse
import os
import sys
import re

# Add ai_engine directory to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from modules.downloader import download_audio_and_thumbnail
from modules.transcriber import transcribe_from_youtube
from modules.analyzer import analyze_transcript
from modules.article_generator import generate_article
from modules.publisher import publish_article
from modules.screenshot_maker import extract_screenshots_simple

def extract_title(html_content):
    match = re.search(r'<h2>(.*?)</h2>', html_content)
    if match:
        return match.group(1)
    return "New Car Review" 

def main(youtube_url):
    print(f"Starting pipeline for: {youtube_url}")
    
    # 1. Download
    # audio_path, thumbnail_path = download_audio_and_thumbnail(youtube_url)
    
    # 2. Transcribe
    # transcript = transcribe_audio(audio_path)
    
    # For testing without wasting API credits/Time, let's mock if needed
    # transcript = "Mock transcript..."
    
    # 3. Analyze
    # analysis = analyze_transcript(transcript)
    
    # 4. Generate Article
    # article_html = generate_article(analysis)
    
    # Mocking for demonstration since we don't have API keys set up
    article_html = "<h2>2026 Future Car Review</h2><p>This is a generated article with a mockup image.</p>"
    
    # 5. Publish
    title = extract_title(article_html)
    
    # Pass thumbnail_path if we had real download
    # publish_article(title, article_html, image_path=thumbnail_path)
    
    # Mock publish
    publish_article(title, article_html)
    
    print("Pipeline finished.")

def check_duplicate(youtube_url):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ —Å—Ç–∞—Ç—å—é —Å —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ.
    """
    # Setup Django if not configured
    import django
    if not django.apps.apps.ready:
        import os
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        sys.path.append(BASE_DIR)
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'auto_news_site.settings')
        django.setup()
    
    from news.models import Article
    
    existing = Article.objects.filter(youtube_url=youtube_url).first()
    if existing:
        print(f"‚ö†Ô∏è  –°—Ç–∞—Ç—å—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {existing.slug} (ID: {existing.id})")
        return existing
    return None


def generate_article_from_youtube(youtube_url):
    """
    Generate article from YouTube URL and return article data.
    Used by Django API.
    
    –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å:
    - –ü—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ–≥–∞–º–∏
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∞–≤—Ç–æ
    - SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    """
    try:
        print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑: {youtube_url}")
        
        # 0. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        existing = check_duplicate(youtube_url)
        if existing:
            return {
                'success': False,
                'error': f'–°—Ç–∞—Ç—å—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {existing.title}',
                'article_id': existing.id,
                'duplicate': True
            }
        
        # 1. –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
        print("üìù –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞...")
        transcript = transcribe_from_youtube(youtube_url)
        
        if not transcript or len(transcript) < 50:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π")
        
        print(f"‚úì –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ–ª—É—á–µ–Ω ({len(transcript)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
        print("üîç –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞...")
        analysis = analyze_transcript(transcript)
        
        if not analysis:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç")
        
        print("‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # 2.5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ —Ç–µ–≥–∏ (–ù–û–í–û–ï!)
        print("üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∏ —Ç–µ–≥–∏...")
        from modules.analyzer import categorize_article, extract_specs_dict
        
        category_name, tag_names = categorize_article(analysis)
        print(f"‚úì –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category_name}")
        print(f"‚úì –¢–µ–≥–∏: {', '.join(tag_names) if tag_names else '–Ω–µ—Ç'}")
        
        # 2.6. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –ë–î (–ù–û–í–û–ï!)
        specs = extract_specs_dict(analysis)
        print(f"‚úì –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {specs['make']} {specs['model']} {specs['year'] or ''}")
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å—é
        print("‚úçÔ∏è  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —Å Groq AI...")
        article_html = generate_article(analysis)
        
        if not article_html or len(article_html) < 100:
            raise Exception("–°—Ç–∞—Ç—å—è –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è")
        
        print(f"‚úì –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ ({len(article_html)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        title = extract_title(article_html)
        
        # 5. –ò–∑–≤–ª–µ–∫–∞–µ–º 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ
        print("üì∏ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –∏–∑ –≤–∏–¥–µ–æ...")
        screenshot_paths = []
        try:
            # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
            screenshots_dir = os.path.join(current_dir, 'output', 'screenshots')
            os.makedirs(screenshots_dir, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –≤–∏–¥–µ–æ
            screenshot_paths = extract_screenshots_simple(youtube_url, screenshots_dir, num_screenshots=3)
            
            if screenshot_paths:
                print(f"‚úì –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(screenshot_paths)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
            else:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–∫—Ä–∏–Ω—à–æ—Ç—ã")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {e}")
            screenshot_paths = []
        
        # 6. –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        summary_lines = [line for line in analysis.split('\n') if line.startswith('Summary:')]
        if summary_lines:
            summary = summary_lines[0].replace('Summary:', '').strip()[:300]
        else:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ —Å—Ç–∞—Ç—å–∏
            import re
            match = re.search(r'<p>(.*?)</p>', article_html, re.DOTALL)
            if match:
                summary = re.sub(r'<[^>]+>', '', match.group(1))[:300]
            else:
                summary = f"Comprehensive review of the {specs['make']} {specs['model']}"
        
        # 7. –ü—É–±–ª–∏–∫—É–µ–º —Å—Ç–∞—Ç—å—é —Å –ü–û–õ–ù–´–ú–ò –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏
        print("üì§ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏...")
        article = publish_article(
            title=title,
            content=article_html,
            summary=summary,
            category_name=category_name,  # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            youtube_url=youtube_url,
            image_paths=screenshot_paths,  # 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ
            tag_names=tag_names,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏
            specs=specs  # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–≤—Ç–æ
        )
        
        print(f"‚úÖ –°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞! ID: {article.id}, Slug: {article.slug}")
        
        return {
            'success': True,
            'article_id': article.id,
            'title': title,
            'slug': article.slug,
            'category': category_name,
            'tags': tag_names
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {str(e)}")
        import traceback
        print(traceback.format_exc())
        return {
            'success': False,
            'error': str(e)
        }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="AI Auto News Generator")
    parser.add_argument("url", help="YouTube Video URL")
    args = parser.parse_args()
    
    main(args.url)
